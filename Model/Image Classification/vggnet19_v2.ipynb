{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import random as rand\n",
    "from random import *\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../Data_Set/Labeld_Crop_Data/\"\n",
    "trDsets = {x: dset.ImageFolder(os.path.join(data_dir, x), train_transforms[x]) for x in ['train', 'val']}\n",
    "trLoaders = {x: torch.utils.data.DataLoader(trDsets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "teDsets = dset.ImageFolder(os.path.join(data_dir, 'test'), transform=test_transforms)\n",
    "teLoaders = torch.utils.data.DataLoader(teDsets, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trDsets_sizes = {x: len(trDsets[x]) for x in ['train', 'val']}\n",
    "class_names = trDsets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "cfgs = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def _vgg(arch, cfg, batch_norm, pretrained, progress, **kwargs):\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "def vgg19(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration \"E\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=22, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg19(num_classes=22)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, factor=0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=8):\n",
    "    \n",
    "    global_info = []\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    early_stopping = EarlyStopping(patience=11, verbose=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        local_info = []\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "                if epoch > 0:\n",
    "                    scheduler.step(val_loss)\n",
    "                    \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in trLoaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / trDsets_sizes[phase]\n",
    "            if phase == 'val':\n",
    "                val_loss = running_loss / trDsets_sizes['val']\n",
    "            epoch_acc = running_corrects.double() / trDsets_sizes[phase]\n",
    "\n",
    "            if phase == 'train':\n",
    "                local_info.append(epoch_loss)\n",
    "                ea = epoch_acc.cpu().numpy()\n",
    "                local_info.append(ea)\n",
    "            else:\n",
    "                local_info.append(epoch_loss)\n",
    "                ea = epoch_acc.cpu().numpy()\n",
    "                local_info.append(ea)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        lr_get = get_lr(optimizer)\n",
    "        print(\"Current learning rate : {:.8f}\".format(lr_get))\n",
    "        global_info.append(local_info)\n",
    "        \n",
    "        if phase =='val':\n",
    "            early_stopping(epoch_loss, model)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 3.0458 Acc: 0.0620\n",
      "val Loss: 2.6734 Acc: 0.0967\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (inf --> 2.673442).  Saving model ...\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 2.4024 Acc: 0.1853\n",
      "val Loss: 1.9648 Acc: 0.2948\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (2.673442 --> 1.964768).  Saving model ...\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 1.8234 Acc: 0.3989\n",
      "val Loss: 1.3722 Acc: 0.5729\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (1.964768 --> 1.372187).  Saving model ...\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 1.2580 Acc: 0.6059\n",
      "val Loss: 0.8689 Acc: 0.7423\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (1.372187 --> 0.868927).  Saving model ...\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.8629 Acc: 0.7284\n",
      "val Loss: 0.7467 Acc: 0.7863\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.868927 --> 0.746657).  Saving model ...\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.6116 Acc: 0.8058\n",
      "val Loss: 0.6593 Acc: 0.8178\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.746657 --> 0.659342).  Saving model ...\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.4457 Acc: 0.8594\n",
      "val Loss: 0.4473 Acc: 0.8753\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.659342 --> 0.447255).  Saving model ...\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.3436 Acc: 0.8915\n",
      "val Loss: 0.3636 Acc: 0.8961\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.447255 --> 0.363561).  Saving model ...\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.2995 Acc: 0.8992\n",
      "val Loss: 0.3803 Acc: 0.8993\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.2476 Acc: 0.9181\n",
      "val Loss: 0.3802 Acc: 0.9053\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.1687 Acc: 0.9441\n",
      "val Loss: 0.2960 Acc: 0.9249\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.363561 --> 0.296032).  Saving model ...\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.1450 Acc: 0.9532\n",
      "val Loss: 0.3209 Acc: 0.9209\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.1219 Acc: 0.9593\n",
      "val Loss: 0.3133 Acc: 0.9249\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.1140 Acc: 0.9620\n",
      "val Loss: 0.2866 Acc: 0.9157\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.296032 --> 0.286580).  Saving model ...\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.0923 Acc: 0.9693\n",
      "val Loss: 0.3321 Acc: 0.9217\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.0948 Acc: 0.9689\n",
      "val Loss: 0.2798 Acc: 0.9329\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.286580 --> 0.279812).  Saving model ...\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.0856 Acc: 0.9733\n",
      "val Loss: 0.4169 Acc: 0.9041\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.0732 Acc: 0.9752\n",
      "val Loss: 0.3429 Acc: 0.9213\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.0668 Acc: 0.9775\n",
      "val Loss: 0.3359 Acc: 0.9137\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 3 out of 11\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.0628 Acc: 0.9795\n",
      "val Loss: 0.2931 Acc: 0.9397\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 4 out of 11\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.0584 Acc: 0.9825\n",
      "val Loss: 0.2520 Acc: 0.9417\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.279812 --> 0.251973).  Saving model ...\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.0563 Acc: 0.9841\n",
      "val Loss: 0.2675 Acc: 0.9365\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.0466 Acc: 0.9855\n",
      "val Loss: 0.2852 Acc: 0.9397\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.0508 Acc: 0.9840\n",
      "val Loss: 0.2812 Acc: 0.9437\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 3 out of 11\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.0405 Acc: 0.9870\n",
      "val Loss: 0.2794 Acc: 0.9429\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 4 out of 11\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.0374 Acc: 0.9888\n",
      "val Loss: 0.2738 Acc: 0.9413\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 5 out of 11\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.0377 Acc: 0.9881\n",
      "val Loss: 0.2879 Acc: 0.9433\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 6 out of 11\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.0353 Acc: 0.9898\n",
      "val Loss: 0.2640 Acc: 0.9445\n",
      "Current learning rate : 0.00010000\n",
      "EarlyStopping counter: 7 out of 11\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.0184 Acc: 0.9942\n",
      "val Loss: 0.2626 Acc: 0.9501\n",
      "Current learning rate : 0.00010000\n",
      "EarlyStopping counter: 8 out of 11\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.0138 Acc: 0.9958\n",
      "val Loss: 0.2608 Acc: 0.9517\n",
      "Current learning rate : 0.00010000\n",
      "EarlyStopping counter: 9 out of 11\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.0134 Acc: 0.9960\n",
      "val Loss: 0.2689 Acc: 0.9513\n",
      "Current learning rate : 0.00010000\n",
      "EarlyStopping counter: 10 out of 11\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.0143 Acc: 0.9952\n",
      "val Loss: 0.2717 Acc: 0.9509\n",
      "Current learning rate : 0.00010000\n",
      "EarlyStopping counter: 11 out of 11\n",
      "Early stopping\n",
      "Training complete in 72m 50s\n",
      "Best val Acc: 0.951658\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, 'lotte_model_vggnet19_v2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = torch.load('lotte_model_vggnet19_v2.pt', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test images: 95 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in teLoaders:\n",
    "        images, labels = data\n",
    "        images, labels = Variable(images.float().cuda()), Variable(labels.float().cuda())\n",
    "        \n",
    "        outputs = testModel(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ID_gum', 1: 'buttering', 2: 'couque_coffee', 3: 'chocopie', 4: 'cidar', 5: 'couque_white', 6: 'coke', 7: 'diget_ori', 8: 'diget_choco', 9: 'gumi_gumi', 10: 'homerunball', 11: 'jjolbyung_noodle', 12: 'juicyfresh', 13: 'jjolbyung_ori', 14: 'spearmint', 15: 'squid_peanut', 16: 'samdasu', 17: 'tuna', 18: 'toreta', 19: 'vita500', 20: 'welchs', 21: 'zec'}\n"
     ]
    }
   ],
   "source": [
    "tag_classes = ['ID_gum', 'buttering', 'couque_coffee', 'chocopie', 'cidar', 'couque_white', 'coke', 'diget_ori', 'diget_choco', 'gumi_gumi', 'homerunball', 'jjolbyung_noodle', 'juicyfresh', 'jjolbyung_ori', 'spearmint', 'squid_peanut', 'samdasu', 'tuna', 'toreta', 'vita500', 'welchs', 'zec']\n",
    "tag_dict = dict()\n",
    "for i, label in enumerate(tag_classes):\n",
    "    tag_dict[i] = label\n",
    "\n",
    "print(tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ID_gum : 96 %\n",
      "Accuracy of buttering : 98 %\n",
      "Accuracy of homerunball : 89 %\n",
      "Accuracy of jjolbyung_noodle : 96 %\n",
      "Accuracy of juicyfresh : 99 %\n",
      "Accuracy of jjolbyung_ori : 96 %\n",
      "Accuracy of spearmint : 97 %\n",
      "Accuracy of squid_peanut : 97 %\n",
      "Accuracy of samdasu : 97 %\n",
      "Accuracy of  tuna : 95 %\n",
      "Accuracy of toreta : 97 %\n",
      "Accuracy of vita500 : 98 %\n",
      "Accuracy of couque_coffee : 96 %\n",
      "Accuracy of welchs : 99 %\n",
      "Accuracy of   zec : 94 %\n",
      "Accuracy of chocopie : 90 %\n",
      "Accuracy of cidar : 98 %\n",
      "Accuracy of couque_white : 95 %\n",
      "Accuracy of  coke : 94 %\n",
      "Accuracy of diget_ori : 86 %\n",
      "Accuracy of diget_choco : 89 %\n",
      "Accuracy of gumi_gumi : 98 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0 for i in range(len(class_names)))\n",
    "class_total = list(0 for i in range(len(class_names)))\n",
    "with torch.no_grad():\n",
    "    for data in teLoaders:\n",
    "        images, labels = data\n",
    "        images, labels = Variable(images.float().cuda()), Variable(labels.float().cuda())\n",
    "        \n",
    "        outputs = model_ft(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "\n",
    "        for i in range(c.size(0)):\n",
    "            label = labels[i]\n",
    "            class_correct[int(label.item())] += c[i].item()\n",
    "            class_total[int(label.item())] += 1\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    print('Accuracy of %5s : %2d %%' % (tag_dict[int(class_names[i])], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

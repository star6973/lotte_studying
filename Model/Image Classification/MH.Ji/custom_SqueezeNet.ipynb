{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import random as rand\n",
    "from random import *\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((400, 400)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((400, 400)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "}\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((400, 400)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../Data_Set/Labeld_Crop_Data/\"\n",
    "trDsets = {x: dset.ImageFolder(os.path.join(data_dir, x), train_transforms[x]) for x in ['train', 'val']}\n",
    "trLoaders = {x: torch.utils.data.DataLoader(trDsets[x], batch_size=64, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "teDsets = dset.ImageFolder(os.path.join(data_dir, 'test'), transform=test_transforms)\n",
    "teLoaders = torch.utils.data.DataLoader(teDsets, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trDsets_sizes = {x: len(trDsets[x]) for x in ['train', 'val']}\n",
    "class_names = trDsets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (6): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Conv2d(512, 22, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.squeezenet1_1(pretrained=False, num_classes=22)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, factor=0.1, patience=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=8, device=device):\n",
    "    \n",
    "    global_info = []\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    early_stopping = EarlyStopping(patience=11, verbose=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        local_info = []\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "                if epoch > 0:\n",
    "                    scheduler.step(val_loss)\n",
    "                    \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in trLoaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / trDsets_sizes[phase]\n",
    "            if phase == 'val':\n",
    "                val_loss = running_loss / trDsets_sizes['val']\n",
    "            epoch_acc = running_corrects.double() / trDsets_sizes[phase]\n",
    "\n",
    "            if phase == 'train':\n",
    "                local_info.append(epoch_loss)\n",
    "                ea = epoch_acc.cpu().numpy()\n",
    "                local_info.append(ea)\n",
    "            else:\n",
    "                local_info.append(epoch_loss)\n",
    "                ea = epoch_acc.cpu().numpy()\n",
    "                local_info.append(ea)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        lr_get = get_lr(optimizer)\n",
    "        print(\"Current learning rate : {:.8f}\".format(lr_get))\n",
    "        global_info.append(local_info)\n",
    "        \n",
    "        if phase =='val':\n",
    "            early_stopping(epoch_loss, model)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.8975 Acc: 0.6876\n",
      "val Loss: 0.9240 Acc: 0.6584\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (inf --> 0.923968).  Saving model ...\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.7195 Acc: 0.7469\n",
      "val Loss: 0.5142 Acc: 0.8262\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.923968 --> 0.514231).  Saving model ...\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.5295 Acc: 0.8163\n",
      "val Loss: 0.4834 Acc: 0.8330\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.514231 --> 0.483361).  Saving model ...\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.4304 Acc: 0.8489\n",
      "val Loss: 0.5989 Acc: 0.7946\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.4257 Acc: 0.8506\n",
      "val Loss: 0.4075 Acc: 0.8538\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.483361 --> 0.407457).  Saving model ...\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.3664 Acc: 0.8700\n",
      "val Loss: 0.4464 Acc: 0.8466\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.2969 Acc: 0.9009\n",
      "val Loss: 0.4101 Acc: 0.8666\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.2956 Acc: 0.8995\n",
      "val Loss: 0.2936 Acc: 0.9037\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.407457 --> 0.293595).  Saving model ...\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.2884 Acc: 0.9075\n",
      "val Loss: 0.2086 Acc: 0.9369\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.293595 --> 0.208621).  Saving model ...\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.2529 Acc: 0.9206\n",
      "val Loss: 0.2395 Acc: 0.9229\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.2312 Acc: 0.9231\n",
      "val Loss: 0.3809 Acc: 0.8622\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.2777 Acc: 0.9099\n",
      "val Loss: 0.3922 Acc: 0.8738\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 3 out of 11\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.1768 Acc: 0.9430\n",
      "val Loss: 0.1866 Acc: 0.9465\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.208621 --> 0.186639).  Saving model ...\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.1799 Acc: 0.9433\n",
      "val Loss: 0.2428 Acc: 0.9273\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.1612 Acc: 0.9486\n",
      "val Loss: 0.2613 Acc: 0.9161\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.1455 Acc: 0.9525\n",
      "val Loss: 0.2080 Acc: 0.9381\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 3 out of 11\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.1633 Acc: 0.9474\n",
      "val Loss: 0.2129 Acc: 0.9393\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 4 out of 11\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.1459 Acc: 0.9526\n",
      "val Loss: 0.2387 Acc: 0.9261\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 5 out of 11\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.1411 Acc: 0.9567\n",
      "val Loss: 0.1877 Acc: 0.9489\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 6 out of 11\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.1364 Acc: 0.9561\n",
      "val Loss: 0.1525 Acc: 0.9628\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.186639 --> 0.152519).  Saving model ...\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.1311 Acc: 0.9569\n",
      "val Loss: 0.1412 Acc: 0.9656\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.152519 --> 0.141201).  Saving model ...\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.1197 Acc: 0.9623\n",
      "val Loss: 0.1521 Acc: 0.9592\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.1220 Acc: 0.9601\n",
      "val Loss: 0.1940 Acc: 0.9433\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.1147 Acc: 0.9642\n",
      "val Loss: 0.1650 Acc: 0.9640\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 3 out of 11\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.1123 Acc: 0.9648\n",
      "val Loss: 0.1324 Acc: 0.9656\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.141201 --> 0.132432).  Saving model ...\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.1110 Acc: 0.9638\n",
      "val Loss: 0.1491 Acc: 0.9676\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.0961 Acc: 0.9698\n",
      "val Loss: 0.1275 Acc: 0.9708\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.132432 --> 0.127478).  Saving model ...\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.0833 Acc: 0.9759\n",
      "val Loss: 0.1476 Acc: 0.9581\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.0850 Acc: 0.9723\n",
      "val Loss: 0.2465 Acc: 0.9265\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.0977 Acc: 0.9699\n",
      "val Loss: 0.2147 Acc: 0.9389\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 3 out of 11\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.1051 Acc: 0.9663\n",
      "val Loss: 0.1244 Acc: 0.9684\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.127478 --> 0.124380).  Saving model ...\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.0984 Acc: 0.9708\n",
      "val Loss: 0.1376 Acc: 0.9656\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.0897 Acc: 0.9727\n",
      "val Loss: 0.1292 Acc: 0.9720\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.1023 Acc: 0.9680\n",
      "val Loss: 0.1694 Acc: 0.9553\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 3 out of 11\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.0992 Acc: 0.9694\n",
      "val Loss: 0.1517 Acc: 0.9612\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 4 out of 11\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.0740 Acc: 0.9788\n",
      "val Loss: 0.1207 Acc: 0.9724\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.124380 --> 0.120712).  Saving model ...\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.0736 Acc: 0.9771\n",
      "val Loss: 0.1369 Acc: 0.9692\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.0835 Acc: 0.9754\n",
      "val Loss: 0.1678 Acc: 0.9549\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.0711 Acc: 0.9782\n",
      "val Loss: 0.1227 Acc: 0.9748\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 3 out of 11\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.0827 Acc: 0.9744\n",
      "val Loss: 0.1138 Acc: 0.9768\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.120712 --> 0.113814).  Saving model ...\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.0832 Acc: 0.9747\n",
      "val Loss: 0.1445 Acc: 0.9636\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.0664 Acc: 0.9800\n",
      "val Loss: 0.1293 Acc: 0.9744\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.0705 Acc: 0.9781\n",
      "val Loss: 0.1828 Acc: 0.9565\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 3 out of 11\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.0666 Acc: 0.9798\n",
      "val Loss: 0.1800 Acc: 0.9640\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 4 out of 11\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.0777 Acc: 0.9749\n",
      "val Loss: 0.1328 Acc: 0.9712\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 5 out of 11\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.0655 Acc: 0.9805\n",
      "val Loss: 0.1084 Acc: 0.9788\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.113814 --> 0.108411).  Saving model ...\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.0624 Acc: 0.9812\n",
      "val Loss: 1.1899 Acc: 0.7974\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.3779 Acc: 0.9006\n",
      "val Loss: 0.2338 Acc: 0.9317\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.1148 Acc: 0.9641\n",
      "val Loss: 0.1394 Acc: 0.9577\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 3 out of 11\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.0799 Acc: 0.9756\n",
      "val Loss: 0.1174 Acc: 0.9704\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 4 out of 11\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.0911 Acc: 0.9727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1233 Acc: 0.9712\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 5 out of 11\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.0832 Acc: 0.9739\n",
      "val Loss: 0.5237 Acc: 0.8801\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 6 out of 11\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.1047 Acc: 0.9706\n",
      "val Loss: 0.1238 Acc: 0.9724\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 7 out of 11\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.0999 Acc: 0.9707\n",
      "val Loss: 0.1539 Acc: 0.9624\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 8 out of 11\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.0830 Acc: 0.9749\n",
      "val Loss: 0.1191 Acc: 0.9760\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 9 out of 11\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.0584 Acc: 0.9824\n",
      "val Loss: 0.1218 Acc: 0.9752\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 10 out of 11\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.0528 Acc: 0.9849\n",
      "val Loss: 0.0942 Acc: 0.9824\n",
      "Current learning rate : 0.00100000\n",
      "Validation loss decreased (0.108411 --> 0.094156).  Saving model ...\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.0542 Acc: 0.9832\n",
      "val Loss: 0.1263 Acc: 0.9740\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 1 out of 11\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.0490 Acc: 0.9856\n",
      "val Loss: 0.1014 Acc: 0.9816\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 2 out of 11\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.0527 Acc: 0.9842\n",
      "val Loss: 0.1030 Acc: 0.9804\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 3 out of 11\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.0511 Acc: 0.9856\n",
      "val Loss: 0.1037 Acc: 0.9788\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 4 out of 11\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.0467 Acc: 0.9859\n",
      "val Loss: 0.1142 Acc: 0.9748\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 5 out of 11\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.0501 Acc: 0.9856\n",
      "val Loss: 0.1059 Acc: 0.9812\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 6 out of 11\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.0503 Acc: 0.9853\n",
      "val Loss: 0.1005 Acc: 0.9784\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 7 out of 11\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.0497 Acc: 0.9858\n",
      "val Loss: 0.1054 Acc: 0.9812\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 8 out of 11\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.0482 Acc: 0.9841\n",
      "val Loss: 0.1205 Acc: 0.9748\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 9 out of 11\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.0428 Acc: 0.9868\n",
      "val Loss: 0.1112 Acc: 0.9780\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 10 out of 11\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.0475 Acc: 0.9845\n",
      "val Loss: 0.1143 Acc: 0.9776\n",
      "Current learning rate : 0.00100000\n",
      "EarlyStopping counter: 11 out of 11\n",
      "Early stopping\n",
      "Training complete in 43m 12s\n",
      "Best val Acc: 0.982421\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, 'lotte_model_squeezenet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = torch.load('lotte_model_squeezenet.pt', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test images: 98.35 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in teLoaders:\n",
    "        images, labels = data\n",
    "        images, labels = Variable(images.float().cuda()), Variable(labels.float().cuda())\n",
    "        \n",
    "        outputs = testModel(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of test images: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ID_gum', 1: 'buttering', 2: 'couque_coffee', 3: 'chocopie', 4: 'cidar', 5: 'couque_white', 6: 'coke', 7: 'diget_ori', 8: 'diget_choco', 9: 'gumi_gumi', 10: 'homerunball', 11: 'jjolbyung_noodle', 12: 'juicyfresh', 13: 'jjolbyung_ori', 14: 'spearmint', 15: 'squid_peanut', 16: 'samdasu', 17: 'tuna', 18: 'toreta', 19: 'vita500', 20: 'welchs', 21: 'zec'}\n"
     ]
    }
   ],
   "source": [
    "tag_classes = ['ID_gum', 'buttering', 'couque_coffee', 'chocopie', 'cidar', 'couque_white', 'coke', 'diget_ori', 'diget_choco', 'gumi_gumi', 'homerunball', 'jjolbyung_noodle', 'juicyfresh', 'jjolbyung_ori', 'spearmint', 'squid_peanut', 'samdasu', 'tuna', 'toreta', 'vita500', 'welchs', 'zec']\n",
    "tag_dict = dict()\n",
    "for i, label in enumerate(tag_classes):\n",
    "    tag_dict[i] = label\n",
    "\n",
    "print(tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ID_gum : 97.42 %\n",
      "Accuracy of buttering : 100.00 %\n",
      "Accuracy of homerunball : 99.57 %\n",
      "Accuracy of jjolbyung_noodle : 100.00 %\n",
      "Accuracy of juicyfresh : 100.00 %\n",
      "Accuracy of jjolbyung_ori : 99.58 %\n",
      "Accuracy of spearmint : 95.40 %\n",
      "Accuracy of squid_peanut : 100.00 %\n",
      "Accuracy of samdasu : 99.51 %\n",
      "Accuracy of  tuna : 97.65 %\n",
      "Accuracy of toreta : 100.00 %\n",
      "Accuracy of vita500 : 98.95 %\n",
      "Accuracy of couque_coffee : 99.57 %\n",
      "Accuracy of welchs : 99.19 %\n",
      "Accuracy of   zec : 98.99 %\n",
      "Accuracy of chocopie : 98.95 %\n",
      "Accuracy of cidar : 98.81 %\n",
      "Accuracy of couque_white : 97.98 %\n",
      "Accuracy of  coke : 97.67 %\n",
      "Accuracy of diget_ori : 90.98 %\n",
      "Accuracy of diget_choco : 95.47 %\n",
      "Accuracy of gumi_gumi : 100.00 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0 for i in range(len(class_names)))\n",
    "class_total = list(0 for i in range(len(class_names)))\n",
    "with torch.no_grad():\n",
    "    for data in teLoaders:\n",
    "        images, labels = data\n",
    "        images, labels = Variable(images.float().cuda()), Variable(labels.float().cuda())\n",
    "        \n",
    "        outputs = model_ft(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "\n",
    "        for i in range(c.size(0)):\n",
    "            label = labels[i]\n",
    "            class_correct[int(label.item())] += c[i].item()\n",
    "            class_total[int(label.item())] += 1\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    print('Accuracy of %5s : %.2f %%' % (tag_dict[int(class_names[i])], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

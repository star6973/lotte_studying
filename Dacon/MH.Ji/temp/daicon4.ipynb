{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "from random import *\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test  = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(\n",
    "    [\n",
    "        pd.get_dummies(train['letter']).values.reshape(-1, 1, 26),\n",
    "        (train[[str(i) for i in range(784)]] / 255.).values.reshape(-1, 1, 784)\n",
    "    ],\n",
    "    axis=2\n",
    ")\n",
    "y_train = train['digit'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor로 형변환\n",
    "x_train = torch.Tensor(x_train)\n",
    "x_valid = torch.Tensor(x_valid)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_valid = torch.LongTensor(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(\n",
    "    x_train[:, :, :26], # Letter\n",
    "    x_train[:, :, 26:].reshape(-1, 1, 28, 28), # Image\n",
    "    y_train # Digit\n",
    ")\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n",
    "\n",
    "valid_data = TensorDataset(\n",
    "    x_valid[:, :, :26],\n",
    "    x_valid[:, :, 26:].reshape(-1, 1, 28, 28),\n",
    "    y_valid\n",
    ")\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1638, 1, 26])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1638, 1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tensors[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1638])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tensors[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Letter의 Convolution Block\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, 3, padding=1), nn.ReLU(), # 8@26\n",
    "            nn.Conv1d(8, 16, 3, padding=1), nn.ReLU(), # 16@26\n",
    "            nn.Conv1d(16, 32, 3, padding=1), nn.ReLU(), # 32@26\n",
    "            nn.Conv1d(32, 64, 3, padding=1), nn.ReLU(), # 64@26\n",
    "            nn.Conv1d(64, 128, 3, padding=1), nn.ReLU(), # 128@26\n",
    "            nn.Conv1d(128, 256, 3, padding=1), nn.ReLU(), # 256@26\n",
    "            nn.Conv1d(256, 128, 3, padding=1), nn.ReLU(), # 128@26\n",
    "            nn.Conv1d(128, 64, 3, padding=1), nn.ReLU(), # 64@26\n",
    "            nn.Conv1d(64, 32, 3, padding=1), nn.ReLU(), # 32@26\n",
    "            nn.Conv1d(32, 16, 3, padding=1), nn.ReLU(), # 16@26\n",
    "            nn.Conv1d(16, 8, 3, padding=1), nn.ReLU(), # 8@26\n",
    "        )\n",
    "        \n",
    "        # Image의 Convolution Block\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), # 16@28x28\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), # 64@28x28\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), # 128@28x28\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(), # 256@28x28\n",
    "            nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(), # 512@28x28\n",
    "            nn.Conv2d(512, 1024, 3, padding=1), nn.ReLU(), # 1024@28x28\n",
    "            nn.Conv2d(1024, 2048, 3, padding=1), nn.ReLU(), # 2048@28x28\n",
    "            nn.Conv2d(2048, 1024, 3, padding=1), nn.ReLU(), # 1024@28x28\n",
    "            nn.Conv2d(1024, 512, 3, padding=1), nn.ReLU(), # 512@28x28\n",
    "            nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(), # 256@28x28\n",
    "            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(), # 128@28x28\n",
    "            nn.Conv2d(128, 64, 3, padding=1), nn.ReLU(), # 64@28x28\n",
    "            nn.Conv2d(64, 32, 3, padding=1), nn.ReLU(), # 32@28x28\n",
    "            nn.Conv2d(32, 16, 3, padding=1), nn.ReLU(), # 16@28x28\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(12752, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, x1, x2, label=False):\n",
    "        out = self._inference(x1, x2)\n",
    "        if label is not False:\n",
    "            loss = self.loss(out, label)\n",
    "            return (out, loss)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def _inference(self, x1, x2):\n",
    "        bsz = x1.size(0)\n",
    "#         print('bsz: ', bsz)\n",
    "        x1 = self.conv1(x1)\n",
    "#         print('x1 shape: ', x1.shape)\n",
    "        x2 = self.conv2(x2)\n",
    "#         print('x2 shape: ', x2.shape)\n",
    "        \n",
    "        x1 = x1.view(bsz, -1)\n",
    "#         print('x1 shape: ', x1.shape)\n",
    "        x2 = x2.view(bsz, -1)\n",
    "#         print('x2 shape: ', x2.shape)\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        out = torch.nn.functional.softmax(self.out(x), dim=1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = customCNN()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_letter = x_train[:32, :, :26].cuda()\n",
    "test_image = x_train[:32, :, 26:].reshape(-1, 1, 28, 28).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_letter.shape)\n",
    "print(test_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(test_letter, test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "optimizer = Adam(\n",
    "    model.parameters(),\n",
    "    lr=2e-5,\n",
    "    eps=1e-8,\n",
    ")\n",
    "\n",
    "epochs = 150\n",
    "seed_val = 42\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "history = defaultdict(list)\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    # train 모드로 변경\n",
    "    model.train()\n",
    "    \n",
    "    # dataloader에서 batch size만큼 반복해서 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # batch를 GPU에 적용\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # batch에서 데이터 추출\n",
    "        letter, image, label = batch\n",
    "        \n",
    "        # Forward Propagation 수행\n",
    "        outputs = model(letter, image, label)\n",
    "        \n",
    "        loss = outputs[1]\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward Propagation 수행\n",
    "        loss.backward()\n",
    "        history[\"train_loss\"].append(loss.item())\n",
    "        \n",
    "        # 정확도 계산\n",
    "        logits = outputs[0].detach().cpu().numpy()\n",
    "        label = label.to(\"cpu\").numpy()\n",
    "        tmp_train_accuracy = flat_accuracy(logits, label)\n",
    "        history[\"train_acc\"].append(tmp_train_accuracy)\n",
    "        \n",
    "        # Gradient Cleeping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # gradient를 통해 weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # gradient 초기화\n",
    "        model.zero_grad()\n",
    "        \n",
    "    # average loss\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    # eval 모드로 변경\n",
    "    model.eval()\n",
    "    \n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy, nb_eval_steps, nb_eval_examples = 0, 0, 0, 0\n",
    "    \n",
    "    # dataloader에서 batch만큼 반복해서 가져옴\n",
    "    for batch in valid_dataloader:\n",
    "        \n",
    "        # batch를 GPU에 적용\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # batch에서 데이터 추출\n",
    "        letter, image, label = batch\n",
    "        \n",
    "        # gradient 계산 안함\n",
    "        with torch.no_grad():\n",
    "            # Forward Propagation 수행\n",
    "            outputs = model(letter, image, label)\n",
    "        \n",
    "        logits = outputs[0]\n",
    "        history[\"eval_loss\"].append(outputs[1].item())\n",
    "        \n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label = label.to(\"cpu\").numpy()\n",
    "        \n",
    "        # 출력 logit과 label을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label)\n",
    "        history[\"eval_acc\"].append(tmp_eval_accuracy)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "        \n",
    "    s = f\"\\r[Epoch {epoch_i+1}/{epochs}]\"\n",
    "    s += f\" Avg Training Loss: {avg_train_loss: .2f}\"\n",
    "    s += \" Valid Acc: {0:.2f}\".format(eval_accuracy / nb_eval_steps)\n",
    "    print(s, end=\"\")\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model/emnist_model4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = customCNN()\n",
    "model.load_state_dict(torch.load(\"./model/emnist_model4.pt\"))\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.concatenate(\n",
    "    [\n",
    "        pd.get_dummies(test[\"letter\"]).values.reshape(-1, 1, 26),\n",
    "        (test[[str(i) for i in range(784)]] / 255.).values.reshape(-1, 1, 784)\n",
    "    ],\n",
    "    axis=2\n",
    ")\n",
    "x_test = torch.Tensor(x_test)\n",
    "\n",
    "x1 = x_test[:, :, :26].cuda()\n",
    "x2 = x_test[:, :, 26:].reshape(-1, 1, 28, 28).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TensorDataset(x1, x2)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for batch in test_dataloader:\n",
    "    input1, input2 = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input1, input2)\n",
    "    y_pred.append(torch.argmax(outputs, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"digit\"] = torch.cat(y_pred).detach().cpu().numpy()\n",
    "submission.to_csv(\"./result/submission4.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
